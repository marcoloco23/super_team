{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/main/lib/python3.9/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import joblib\n",
    "from helpers import flatten_performance_df, stack_df, get_performances_by_team\n",
    "from sklearn.metrics import r2_score\n",
    "client = pymongo.MongoClient(\"mongodb+srv://superteam:4NgVPcNjmKBQkMTd@cluster0.sfhws.mongodb.net/dev?retryWrites=true&w=majority\")\n",
    "db = client.superteam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_performances = pd.DataFrame(list(db.playerPerformances.find({}))).set_index('_id')\n",
    "team_performances = pd.DataFrame(list(db.teamPerformances.find({}))).set_index('_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(team_performances.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_performance_df(performance_df):\n",
    "    if len(performance_df.columns) == 10:\n",
    "        i = 6\n",
    "    if len(performance_df.columns) == 13:\n",
    "        i = 9\n",
    "    percentages = performance_df.PERCENTAGES.apply(pd.Series)\n",
    "    absolutes_stats = performance_df.ABSOLUTE_STATISTICS.apply(pd.Series)\n",
    "    ratings = performance_df.RATINGS.apply(pd.Series)\n",
    "    misc = performance_df.MISC.apply(pd.Series)\n",
    "    performance_df = pd.concat(\n",
    "        [performance_df.iloc[:, :i], percentages, absolutes_stats, ratings, misc],\n",
    "        axis=1,\n",
    "    )\n",
    "    return performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_performances = flatten_performance_df(player_performances)\n",
    "team_performances = flatten_performance_df(team_performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_ids = list(set(team_performances.GAME_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performances_by_team(performance_df):\n",
    "    if len(performance_df.columns) == 93:\n",
    "        i = 6\n",
    "    if len(performance_df.columns) == 114:\n",
    "        i = 9\n",
    "    team_list = performance_df[\"TEAM_ABBREVIATION\"].astype(\"category\").cat.categories\n",
    "    team_1_performances = performance_df[\n",
    "        performance_df[\"TEAM_ABBREVIATION\"] == team_list[0]\n",
    "    ]\n",
    "    team_2_performances = performance_df[\n",
    "        performance_df[\"TEAM_ABBREVIATION\"] == team_list[1]\n",
    "    ]\n",
    "    team_1_performances = (\n",
    "        team_1_performances.iloc[:, i:]\n",
    "        .apply(pd.to_numeric)\n",
    "        .sort_values(\"MIN\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    team_2_performances = (\n",
    "        team_2_performances.iloc[:, i:]\n",
    "        .apply(pd.to_numeric)\n",
    "        .sort_values(\"MIN\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return team_1_performances, team_2_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 647/647 [00:43<00:00, 14.77it/s]\n"
     ]
    }
   ],
   "source": [
    "player_count = 13\n",
    "feature_list,target_list = [],[]\n",
    "for game_id in tqdm(game_ids):\n",
    "    player_game_performances = player_performances[player_performances.GAME_ID==game_id]\n",
    "    team_game_performances = team_performances[team_performances.GAME_ID==game_id].drop_duplicates()\n",
    "    \n",
    "    team_1_performances, team_2_performances = get_performances_by_team(team_game_performances)\n",
    "    team_1_player_performances, team_2_player_performances = get_performances_by_team(player_game_performances)\n",
    "\n",
    "    team_1_player_performances = team_1_player_performances[:player_count]\n",
    "    team_2_player_performances = team_2_player_performances[:player_count]\n",
    "    \n",
    "    for i in [team_1_player_performances,team_2_player_performances]:\n",
    "        feature_list.append(stack_df(i))\n",
    "\n",
    "    for i in [team_1_performances,team_2_performances]:\n",
    "        target_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.concat(feature_list).fillna(0).reset_index(drop=True)\n",
    "targets = pd.concat(target_list).fillna(0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, targets, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030405920139974427"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(train_features.corrwith(train_labels.PIE)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "multioutputregressor = MultiOutputRegressor(xgb.XGBRegressor(objective='reg:squarederror')).fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/team_13_model.pkl']"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(multioutputregressor, \"models/team_13_nba_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.83934004187352\n"
     ]
    }
   ],
   "source": [
    "# predicting\n",
    "print(np.mean(abs(multioutputregressor.predict(test_features) - test_labels), axis=0).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "multioutputregressor = joblib.load(\"models/team_13_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = pd.DataFrame(multioutputregressor.predict(test_features), columns=test_labels.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.374381268852182\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(test_labels, prediction_df)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3565170736576697"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(prediction_df.PTS,test_labels.reset_index(drop=True).PTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping from individual performance to team performance is bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9450414bf23f3dd29b5b05a150ab805ddf54e50a477ec96525535ab209d16c9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('main')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
