{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 v 5 elimination matches until 1 winner is declared, then change all teams except winning team and redo. See who emerges as winner after n interations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "client = pymongo.MongoClient(\"mongodb+srv://superteam:4NgVPcNjmKBQkMTd@cluster0.sfhws.mongodb.net/dev?retryWrites=true&w=majority\")\n",
    "db = client.superteam\n",
    "import pandas as pd\n",
    "from nba_api.stats.static import players\n",
    "from helpers import flatten_performance_df, stack_df,make_data_relative, get_average_minute_weighted_player_performances\n",
    "import numpy as np\n",
    "from constants import TEAM_FEATURES\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from nba_api.stats.endpoints import leaguegamefinder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamefinder = leaguegamefinder.LeagueGameFinder()\n",
    "all_games = gamefinder.get_data_frames()[0]\n",
    "current_season = all_games[all_games.SEASON_ID==\"22021\"]\n",
    "games = list(set(current_season.GAME_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('models/team_13_model.pkl')\n",
    "starting_5_model = joblib.load('models/starting_5_team_model.pkl')\n",
    "relative_master_model = xgb.XGBRegressor()\n",
    "relative_master_model.load_model('models/relative_master_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_features(model, starting_5_features):\n",
    "    team_features = model.predict(starting_5_features)\n",
    "    team_features = pd.DataFrame(team_features, columns=TEAM_FEATURES)\n",
    "    team_features.pop('PLUS_MINUS')\n",
    "    return team_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_players = players.get_active_players()\n",
    "active_players =pd.DataFrame(active_players)\n",
    "active_player_ids = active_players.id.to_list()\n",
    "active_player_performances = pd.DataFrame(list(db.playerPerformances.find({'PLAYER_ID':{'$in': active_player_ids}}))).set_index('_id')\n",
    "performances = flatten_performance_df(active_player_performances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maybe this isnt the best way to identify average performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_performances = performances[performances.GAME_ID.isin(games)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "minute_scaled_df = get_average_minute_weighted_player_performances(performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_player_performances(performances):\n",
    "    weighted_performances = performances.copy()\n",
    "    group = weighted_performances.groupby([\"PLAYER_ID\", \"PLAYER_NAME\"], axis=0)\n",
    "    mean_df = group.mean()\n",
    "    mean_df = mean_df.dropna().reset_index().drop('TEAM_ID',axis=1)\n",
    "    return mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_performances = get_average_player_performances(season_performances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min cannot be bigger than 240, scale all minutes to 240 but pct dont scale with minutes only absolute values do, therefore handle when training model, by removing MIN information in target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tournament(performances, rounds=1, team_count=32):\n",
    "    winner = False\n",
    "    winner_list = []\n",
    "\n",
    "    for round in tqdm(range(rounds)):\n",
    "        player_pool = performances[['PLAYER_ID','PLAYER_NAME']]\n",
    "        team_list = []\n",
    "        team_number = team_count\n",
    "\n",
    "        if winner:\n",
    "            player_pool.drop(winner_team.index)\n",
    "            team_list.append(winner_team)\n",
    "            team_number = team_number-1\n",
    "\n",
    "        for n in range(team_number):\n",
    "            player_ids = player_pool.sample(13).PLAYER_ID\n",
    "            team = performances[performances[\"PLAYER_ID\"].isin(player_ids)]\n",
    "            player_pool = player_pool.drop(team.index)\n",
    "            team_list.append(team)\n",
    "\n",
    "        for i in range(int(np.log2(team_count))):\n",
    "            it = iter(team_list)\n",
    "            team_list = []\n",
    "            for (teamA, teamB)  in zip(it,it):\n",
    "                team_A, team_A_features = teamA.iloc[:,:2], stack_df(teamA.iloc[:,2:].reset_index(drop=True))\n",
    "                team_B, team_B_features = teamB.iloc[:,:2], stack_df(teamB.iloc[:,2:].reset_index(drop=True))\n",
    "\n",
    "                # print('Team A: ',teamA.sort_values('MIN',ascending=False).PLAYER_NAME.to_list(), '\\nTeam B: ', teamB.sort_values('MIN',ascending=False).PLAYER_NAME.to_list())\n",
    "\n",
    "                team_A_features = get_team_features(model,team_A_features)\n",
    "                team_B_features = get_team_features(model,team_B_features)\n",
    "                \n",
    "                team_features = make_data_relative(pd.concat([team_A_features,team_B_features])).reset_index(drop=True)\n",
    "\n",
    "                plus_minus_result = relative_master_model.predict(team_features)\n",
    "                diff = int(abs(plus_minus_result).mean())\n",
    "                if plus_minus_result[0]>plus_minus_result[1]:\n",
    "                    team_list.append(teamA)\n",
    "                    # print('Team A wins')\n",
    "                else:\n",
    "                    team_list.append(teamB)\n",
    "                    # print('Team B wins')\n",
    "\n",
    "        if len(team_list)==1:\n",
    "            winner_team = team_list[0]\n",
    "            print('Winner Team: ',winner_team.sort_values('MIN',ascending=False).PLAYER_NAME.to_list())\n",
    "            winner = True\n",
    "            winner_list.append(winner_team.sort_values('MIN',ascending=False))\n",
    "\n",
    "    return winner_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = run_tournament(average_performances, rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_features = get_team_features(model,stack_df(winners[-3].iloc[:,2:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify why some team dominate, add budget caps, once a team has been identified, find its win statisitics by matching it up against 1000s of other teams and recording results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_team = minute_scaled_df[minute_scaled_df[\"PLAYER_ID\"].isin([2544,201142, 202681, 201935, 203954])]\n",
    "winner_features = get_team_features(starting_5_model,stack_df(winner_team.iloc[:,2:].reset_index(drop=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [05:24<00:00,  3.08it/s]\n"
     ]
    }
   ],
   "source": [
    "team = get_average_player_performances(season_performances[season_performances.TEAM_ABBREVIATION=='CHA']).sort_values('MIN',axis=0,ascending=False)[:13]\n",
    "\n",
    "player_pool = average_performances[['PLAYER_ID','PLAYER_NAME']]\n",
    "win_loss_stats = []\n",
    "plus_minus_stats = []\n",
    "better_teams = []\n",
    "\n",
    "for i in tqdm(range(1000)):\n",
    "    player_ids = player_pool.sample(13).PLAYER_ID\n",
    "    opponent_team = average_performances[average_performances[\"PLAYER_ID\"].isin(player_ids)]\n",
    "    team_A, team_A_features = team.iloc[:,:2], stack_df(team.iloc[:,2:].reset_index(drop=True))\n",
    "    team_B, team_B_features = opponent_team.iloc[:,:2], stack_df(opponent_team.iloc[:,2:].reset_index(drop=True))\n",
    "\n",
    "    team_A_features = get_team_features(model,team_A_features)\n",
    "    team_B_features = get_team_features(model,team_B_features)\n",
    "    \n",
    "    team_features = make_data_relative(pd.concat([team_A_features,team_B_features])).reset_index(drop=True)\n",
    "\n",
    "    plus_minus_result = relative_master_model.predict(team_features)\n",
    "    if plus_minus_result[0]>plus_minus_result[1]:\n",
    "        win_loss_stats.append(1)\n",
    "        plus_minus_stats.append(np.round(plus_minus_result[0]))\n",
    "    else:\n",
    "        better_teams.append(opponent_team)\n",
    "        plus_minus_stats.append(np.round(plus_minus_result[1]))\n",
    "        win_loss_stats.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.782\n",
      "2.095\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(win_loss_stats))\n",
    "print(np.mean(plus_minus_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9450414bf23f3dd29b5b05a150ab805ddf54e50a477ec96525535ab209d16c9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('main')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
